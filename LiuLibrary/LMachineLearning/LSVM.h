/// @file LSVM.h
/// @brief  支持向量机
/// 
/// Detail:
/// @author Burnell_Liu  
/// @version   
/// @date 6:7:2015


#ifndef _LSVM_H_
#define _LSVM_H_

#include "LDataStruct/LMatrix.h"

#ifndef IN
#define IN
#endif

#ifndef INOUT
#define INOUT
#endif

#ifndef OUT
#define OUT
#endif

typedef LMatrix<float> LSVMMatrix;

/// @brief SVM原始问题结构
struct LSVMProblem
{
    /// @brief 构造函数
    ///  
    /// @param[in] sampleMatrix 样本矩阵, 每一行为一个样本, 每行中的值为样本的特征值
    /// @param[in] classVector 类别向量(列向量), 行数为样本矩阵的行数, 列数为1, 只能为-1.0f或1.0f
    LSVMProblem(IN const LSVMMatrix& sampleMatrix, IN const LSVMMatrix& classVector)
		: XMatrix(sampleMatrix), YVector(classVector)
    {
    }

    const LSVMMatrix& XMatrix; ///< 样本矩阵
    const LSVMMatrix& YVector; ///< 类别向量(列向量)
};

/// @brief SVM参数结构
struct LSVMParam;
/// @brief SVM解结构
struct LSVMSolution;

/// @brief 核函数
class LSVMKernelFunc
{
public:
    /// @brief 转换
    ///  
    /// 要求向量A和B的长度相同, 并且都是行向量
    /// @param[in] vectorA 向量A(行向量)
    /// @param[in] vectorB 向量B(行向量)
    /// @return 返回向量A, B映射在高纬空间上的向量的内积
    virtual float Translate(IN const LSVMMatrix& vectorA, IN const LSVMMatrix& vectorB) const = 0;
};

/// @brief 径向基函数
///
/// 默认gamma值为0.1
class LSVMRBF : public LSVMKernelFunc
{
public:
    LSVMRBF();
    ~LSVMRBF();

    /// @brief 设置gamma参数
    ///  
    /// gamma选的很小则可以将任意的数据映射为线性可分, 但是会产生过拟合的问题
    /// gamma选的很大则高次特征的权重衰减的很快
    /// @param[in] gamma
    void SetGamma(IN float gamma);

    /// @brief 转换
    ///  
    /// 要求向量A和B的长度相同, 并且都是行向量
    /// @param[in] vectorA 向量A(行向量)
    /// @param[in] vectorB 向量B(行向量)
    /// @return 返回向量A, B映射在高纬空间上的向量内积
    virtual float Translate(IN const LSVMMatrix& vectorA, IN const LSVMMatrix& vectorB) const;

private:
    float m_gamma; ///< gamma参数
};

/// @brief 支持向量机
class LSVM
{
public:
    LSVM();
    ~LSVM();
    /// @brief 训练模型
    ///  
    /// problem参数中的样本矩阵的行数要和标签向量的行数相同
    /// 该函数可能很耗时, 视问题的复杂度而定
    /// @param[in] problem 原始问题
    /// @param[in] pKernelFunc 核函数, 如果为空则不使用核函数
    /// @return 成功返回true, 失败返回false(参数错误的情况下会返回失败)
    bool TrainModel(IN const LSVMProblem& problem, IN const LSVMKernelFunc* pKernelFunc);

    /// @brief 使用训练好的模型进行预测
    ///  
    /// 请保证需要预测的样本的特征长度和训练样本的特征长度相同
    /// @param[in] sample 需要预测的样本
    /// @return 返回预测结果: -1.0 or 1.0, 返回0.0表示出错(需要预测的样本出错或者模型没有训练好)
    float Predict(IN const LSVMMatrix& sample);


    /// @brief 获取支持向量数
    ///  
    /// @return 支持向量的数目, 返回0表示模型没被训练好
    unsigned int GetSupportVectorNumber();

private:

    /// @brief 产生一个不等于i的随机数, 范围[0, max]
    ///  
    /// @param[in] i 随机数中被过滤的值
    /// @param[in] max 随机数中的最大值, 要求大于0
    /// @return 随机数
    int SelectRand(IN unsigned int i, IN unsigned int max);

    /// @brief 使用启发式方法选择第二个alpha
    ///  
    /// @param[in] i 第一个alpha索引
    /// @param[in] E 所有样本误差向量
    /// @return 第二个alpha索引
    unsigned int SelectSecondAlpha(IN unsigned int i, IN const LSVMMatrix& E);

    /// @brief 修正a值
    ///  a应处于min~max, 当a > max时a = max, 当a < min时a = min
    /// @param[in]  a 需要修正的值
    /// @param[in] min 最小值
    /// @param[in] max 最大值
    /// @return 修正后的值
    float ClipAlpha(IN float a, IN float min, IN float max);

    /// @brief 根据解计算出所有样本的误差
    /// 
    /// @param[in] problem 原始问题
    /// @param[in] solution 解
    /// @param[in] k 样本索引
    /// @return 误差值
    void CalculateError(IN const LSVMProblem& problem, IN const LSVMSolution& solution, OUT LSVMMatrix& errorVector);

    /// @brief SMO训练算法(示例)
    ///  
    /// 该示例代码没有使用启发式的方法选择alpha, 也没有使用核函数, 该函数仅用来参考用
    /// @param[in] sampleMatrix 样本矩阵, 每一行为一个样本, 每行中的值为样本的特征值
    /// @param[in] classVector 类别向量(列向量), 行数为样本矩阵的行数, 列数为1, 只能为-1.0f或1.0f
    /// @param[in] C 常数C
    /// @param[in] toler 容错率
    /// @param[out] b 超平面截距
    /// @param[out] alphaVector alpha向量
    void SMOTrainModelExample(
        IN const LSVMMatrix& sampleMatrix, 
        IN const LSVMMatrix& classVector, 
        IN float C, 
        IN float toler, 
        OUT float& b,
        OUT LSVMMatrix& alphaVector);

    /// @brief SMO训练算法
    ///  
    /// @param[in] problem 原始问题
    /// @param[in] param 参数
    /// @param[out] solution 问题的解
    void SMOTrainModel(IN const LSVMProblem& problem, IN const LSVMParam& param, OUT LSVMSolution& solution);

    /// @brief SMO优化Alpha
    ///  
    /// @param[in] fristAlpha 需要优化的alpha的索引
    /// @param[in] problem 原始问题
    /// @param[in] param 参数
    /// @param[in] error 误差缓存向量
    /// @param[out] solution 问题的解
    /// @return 成功优化返回true, 优化失败返回false
    bool SMOOptimizeAlpha(
        IN unsigned int fristAlpha, 
        IN const LSVMProblem& problem, 
        IN const LSVMParam& param, 
        IN const LSVMMatrix& error,
        OUT LSVMSolution& solution);

private:
    const LSVMProblem* m_pProblem; ///< 原始问题
    LSVMParam* m_pParam; ///< 参数
    LSVMSolution* m_pSolution; ///< SVM的解
    LSVMMatrix* m_pKMatrix; ///< K矩阵
    const LSVMKernelFunc* m_pKernelFunc; ///< 核函数
    bool m_bUseKernelFunc; ///< 是否使用核函数的标识符
    LSVMMatrix m_supportVectorIndex; ///< 记录支持向量的样本的索引(列向量)
};

#endif
